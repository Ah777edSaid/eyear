# -*- coding: utf-8 -*-
"""*eyEar-main .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ojZfo4aSyCcQeObQKSpXZe0rK9nC1Fde

engineers_team .....  ( eyEar_project  )
- Ah777ed_said
- menna_ehab
- Ahmed negm
-


#preparing environment
"""

# Flag to control whether to run the example usage
run_example_usage = 0# Change this to 0/1 to disable/enable the example usage

'''
from google.colab import drive
drive.mount('/content/drive')
'''


"""###import packages"""

# Basic Imports
import os
import time
import numpy as np
from datetime import datetime
import pytz
import requests
import io
import re
import string
import nltk


# Image Processing
from PIL import Image, ImageFilter
import cv2

# Transformers for Image Processing and Translation
import torch
from transformers import (
    BlipProcessor,
    BlipForConditionalGeneration,
    AutoTokenizer,
    AutoModelForCausalLM,
    BlipForQuestionAnswering,
    DetrImageProcessor,
    DetrForObjectDetection
)

# Text-to-Speech and Sound
from playsound import playsound
from gtts import gTTS
from pydub import AudioSegment

# Translation and OCR
from googletrans import Translator
import pytesseract

# Real-ESRGAN for Image Enhancement (if necessary, ensure it’s installed)
# from realesrgan import RealESRGANer  # Uncomment if needed

# NLP Libraries
from textblob import TextBlob
from word2number import w2n

# Voice Recognition
import speech_recognition as sr

# Firebase Setup for Intent Detection
import pyrebase
import firebase_admin
from firebase_admin import credentials, db

# Additional Libraries for Object Detection and NLP
from ultralytics import YOLO
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, accuracy_score
import joblib

# Web Scraping
from bs4 import BeautifulSoup
from transformers import pipeline
import gc

"""##Requests"""

class ImageDownloader:
    def __init__(self, urls, retries=3):
        self.urls = urls  # List of URLs to download
        self.retries = retries  # Number of retries in case of failure

    def download_image(self, url, image_number):
        """Download an image from the URL and save it locally."""
        for i in range(self.retries):
            try:
                # Send a GET request to the URL
                response = requests.get(url)
                response.raise_for_status()  # Check if the request was successful

                # Save the image in Colab's content directory
                filename = f'/content/image_{image_number}.jpg'  # Colab's file path
                with open(filename, 'wb') as file:
                    file.write(response.content)

                print(f"Image downloaded and saved as '{filename}'")
                return filename  # Return the saved file path after successful download

            except requests.exceptions.RequestException as e:
                print(f"Attempt {i+1} failed for {url}: {e}")
                if i < self.retries - 1:
                    print("Retrying...")
                    time.sleep(2)  # Wait for 2 seconds before retrying
                else:
                    print("Failed to download the image after multiple attempts.")
                    return None  # Return None if the download failed after retries

    def download_all_images(self):
        """Download all images from the URLs list."""
        downloaded_images = []
        for index, url in enumerate(self.urls, start=1):
            downloaded_file = self.download_image(url, index)
            if downloaded_file:
                downloaded_images.append(downloaded_file)
        return downloaded_images

    def download_and_show(self):
        """Download all images and provide paths for further use."""
        downloaded_images = self.download_all_images()
        if downloaded_images:
            print(f"All images downloaded: {downloaded_images}")
        else:
            print("No images were successfully downloaded.")


if run_example_usage:
    # Example Usage
    if 0:
        urls = [
            'https://th.bing.com/th/id/OIP.PmJr-EUmcMHusLq-EOVdDQHaDp?rs=1&pid=ImgDetMain',
            'https://th.bing.com/th/id/OIP.PmJr-EUmcMHusLq-EOVdDQHaDp?rs=1&pid=ImgDetMain',
            'https://th.bing.com/th/id/OIP.PmJr-EUmcMHusLq-EOVdDQHaDp?rs=1&pid=ImgDetMain'
            ]
        # Initialize ImageDownloader class
        image_downloader = ImageDownloader(urls)

        # Download all images
        image_downloader.download_and_show()

"""## database firebase"""

#firebase config


# Firebase configuration
config = {
  'apiKey': "AIzaSyCBvKO1K2FJ_MoPXAckuga40mwG593Qo7o",
  'authDomain': "eyear-87a0e.firebaseapp.com",
  'databaseURL': "https://eyear-87a0e-default-rtdb.firebaseio.com",
  'projectId': "eyear-87a0e",
  'storageBucket': "eyear-87a0e.appspot.com",
  'messagingSenderId': "337767300301",
  'appId': "1:337767300301:web:050cb7adf9c7d0e3b8bd84",
  'measurementId': "G-8SRQ7WFTPK"
}

# Initialize Firebase
firebase = pyrebase.initialize_app(config)
db = firebase.database()  # Using Realtime Database

print("Firebase initialized successfully.")

# JSON content as a string
json_content = """
{
  "apiKey": "AIzaSyCBvKO1K2FJ_MoPXAckuga40mwG593Qo7o",
  "authDomain": "eyear-87a0e.firebaseapp.com",
  "databaseURL": "https://eyear-87a0e-default-rtdb.firebaseio.com",
  "projectId": "eyear-87a0e",
  "storageBucket": "eyear-87a0e.appspot.com",
  "messagingSenderId": "337767300301",
  "appId": "1:337767300301:web:050cb7adf9c7d0e3b8bd84",
  "measurementId": "G-8SRQ7WFTPK",
  "type": "service_account",
  "project_id": "eyear-87a0e",
  "private_key_id": "9e6c262904034236feaf43a2745a1511dace0ffe",
  "private_key": "-----BEGIN PRIVATE KEY-----\\nMIIEvQIBADANBgkqhkiG9w0BAQEFAASCBKcwggSjAgEAAoIBAQDDtRpvGYatkBtT\\nver2hhIv8NBLeD8M+v1U62FbIyFT4E10+/HlZV57WyrDQOZQaY883nhgQKuMvl//\\n1MqSwP4cM2FOl465v1wOBpdYcqing56IhluGL5hbq56PJXNhls96SsH2NYNJypO3\\nnkGIwwN8dBLNxzgE18K0eayDNccg/MXzIY76EN4oj4DkcdxMBQe9Na0WwDxpDZQ3\\noFuUYmJqQIcMYnljh9CGoVzeHRcCprQOp8aJANnGPLGoipgF6Xh0AFi+VJWVqwXx\\nFY7cNsuCxGbeYa7prVMypQg6D8DDVpZv+mKmVQ30qtEa1I48vHGmitQBQ7X4xaFT\\nxPw1PlQLAgMBAAECggEACOdE0Bgbseqz64/g0B1SV37/oudSCv+iJcpdj/1dp0i1\\njWRm4VZGwZroq6BYugDLZOwEEvDuPQVuLZ/bJWkFRngp7Z7kfdvQTs0K9pmkxZYt\\n0K04HbctmcIJgR6ljKOFRd1/zHkrw2Albz2SYqvojTFkp5rwF/xO3dIJQKDiMcRp\\nyDl24Jadfbn+gXOfagxV0VmpG6iFyeXB3JwgV5gRMvO2c2z4b03oZb2WIEDS76q7\\nrXpjsUuLd39oRjS2/ai804QwrPDcjvVbcl1FxINu5FLh2Xpg16Ga9o0dQFobXzcN\\nDawbvDXwY53j/2WxcJ44DjIdQfp8SzA00ta7lZ5q5QKBgQDkX4mEDLJRCUN0PbO6\\n3y8diMzgKeKjdE2CTtzU1E2ODe9ysPLGBTnDIULqyPS9Pu5FwOANX9EeQ8+omapK\\nUh61SpVcCnet5Pxg/9i6L4CdP0Hx97GJxoXMvBS/AUVcCQ96Pt+oQw30DVLWS5g2\\nZWWoMJa7IvF3r7OakwmQMbjtnwKBgQDbYfGsuy7j/HAighF40Z38mzth9Kr8ZF40\\n/t/dfutVJzfYHM5gW74WAy+pb1xeA/lmQezjIcgozye4glHXF/luF8WOUI8zAd9s\\nKwElD4XDILYskt3L7M7HJbeV0Hq8iaSidkvDgTqZfbVYgQqOglI4qRH7PODWjFgL\\n5pfApPFqFQKBgEQFMLBkF7iLScwVlLLURvRFCsC5uQd2XJ+zXZMGqRLmk6tViPny\\nFIJKJeRIdpznYZDlIdbZ8y9Qg0l0e4QncX4N+O6xL3Rb/8/kZGkQPP6ZGMs5O2gN\\n+UxBuOwrNL109Wcz0uoLDtziGwo4+d051k2CK2MRxVogux4PLYoFRU+BAoGBANpd\\nbmJBWxYhgjhHAT8iXsA+f2gsUjmxabgUbh4ZpAL5a3OYkK+HAfkFKN7c8rK9//QR\\n8MnQKVy9fcsBJJcVzPgRf1n9w9vApHQVhikufzVPjSVm9pBx4QyG9WqQvmqGEzKG\\nzzkFm5+GaghzQV/CRjcRys0ptp63yTfnSeu+AnJVAoGAbna63YIV9T56tJif0Pcr\\nMCadWPNZcS2ouTlh59gpzfeyQHDtH8cKwCz6zywWUhOTL8LK/sdyZh56k8hHYbRv\\nFt5M4SLMbNUu/kK2fckzELvCs0F0rlnnrMzrH3j8qgnnoZc/NHMaYgEQAFqwEDN5\\nwbaqBuzcNb3wD42qisquRt8=\\n-----END PRIVATE KEY-----\\n",
  "client_email": "firebase-adminsdk-ryxnv@eyear-87a0e.iam.gserviceaccount.com",
  "client_id": "111654604269586112994",
  "auth_uri": "https://accounts.google.com/o/oauth2/auth",
  "token_uri": "https://oauth2.googleapis.com/token",
  "auth_provider_x509_cert_url": "https://www.googleapis.com/oauth2/v1/certs",
  "client_x509_cert_url": "https://www.googleapis.com/robot/v1/metadata/x509/firebase-adminsdk-ryxnv%40eyear-87a0e.iam.gserviceaccount.com",
  "universe_domain": "googleapis.com"
}
"""

print("JSON content as a string done.")

"""###intent database"""

# إضافة بيانات التدريب
def add_training_data():
    training_data = [
        # Image Assistant and Captioning Intents
        {"id": "1", "text": "Describe the place I'm in.", "intent": "image_assistant"},
        {"id": "2", "text": "What does this environment look like?", "intent": "image_assistant"},
        {"id": "3", "text": "Can you tell me about the scene around me?", "intent": "image_assistant"},
        {"id": "4", "text": "Describe the atmosphere in this photo.", "intent": "image_assistant"},
        {"id": "5", "text": "What are the key elements in this scene?", "intent": "image_assistant"},
        {"id": "6", "text": "What can you see in this location?", "intent": "image_assistant"},
        {"id": "7", "text": "Summarize the surroundings I’m currently seeing.", "intent": "image_assistant"},
        {"id": "8", "text": "Explain the background of this scene.", "intent": "image_assistant"},
        {"id": "9", "text": "What details are visible here?", "intent": "image_assistant"},
        {"id": "10", "text": "Describe the landscape I’m currently seeing.", "intent": "image_assistant"},
        {"id": "11", "text": "Where is the object in front of me?", "intent": "image_assistant"},

        # OCR Intents
        {"id": "12", "text": "Read the text that I see.", "intent": "text_extraction"},
        {"id": "13", "text": "Can you extract any words from this view?", "intent": "text_extraction"},
        {"id": "14", "text": "What text is written here?", "intent": "text_extraction"},
        {"id": "15", "text": "Identify the text that appears in front of me.", "intent": "text_extraction"},
        {"id": "16", "text": "Is there any readable content in this area?", "intent": "text_extraction"},
        {"id": "17", "text": "Extract the written content from what I see.", "intent": "text_extraction"},
        {"id": "18", "text": "What does the text say in this context?", "intent": "text_extraction"},

        # General Knowledge Questions Intents
        {"id": "19", "text": "Who is the current president of the United States?", "intent": "general_knowledge"},
        {"id": "20", "text": "What is the capital of France?", "intent": "general_knowledge"},
        {"id": "21", "text": "How many continents are there?", "intent": "general_knowledge"},
        {"id": "22", "text": "What is the largest planet in our solar system?", "intent": "general_knowledge"},
        {"id": "23", "text": "When was the Declaration of Independence signed?", "intent": "general_knowledge"},
        {"id": "24", "text": "What is the boiling point of water?", "intent": "general_knowledge"},
        {"id": "25", "text": "Who wrote 'Hamlet'?", "intent": "general_knowledge"},
        {"id": "26", "text": "Where is London?", "intent": "general_knowledge"},

        # Time Intents
        {"id": "27", "text": "What time is it?", "intent": "time"},
        {"id": "28", "text": "Can you tell me the current time?", "intent": "time"},
        {"id": "29", "text": "What time zone am I in?", "intent": "time"},
        {"id": "30", "text": "What's the time difference between here and London?", "intent": "time"},
        {"id": "31", "text": "How many hours until midnight?", "intent": "time"},
        {"id": "32", "text": "What clock is now?", "intent": "time"},
        {"id": "33", "text": "What time is sunset exactly today?", "intent": "time"},
        {"id": "34", "text": "When exactly does daylight saving time end this year?", "intent": "time"},
        {"id": "35", "text": "Can you give me the precise time difference between New York and Tokyo?", "intent": "time"},
        {"id": "36", "text": "How many exact minutes have passed since noon?", "intent": "time"},
        {"id": "37", "text": "If it’s 9 AM in London, what is the exact time for my meeting tomorrow?", "intent": "time"},
        {"id": "38", "text": "What will the exact time be in 5 hours from now?", "intent": "time"},
        {"id": "39", "text": "What is the precise moment when daylight saving time starts this year?", "intent": "time"},
        {"id": "40", "text": "What is the exact current time in Sydney, down to the second?", "intent": "time"},
        {"id": "41", "text": "How many days exactly until the next leap year begins?", "intent": "time"},
        {"id": "42", "text": "Can you tell me the exact difference in hours between my location and Paris?", "intent": "time"},
        {"id": "43", "text": "What is the exact date and time right now?", "intent": "time"},
        {"id": "44", "text": "How many exact hours are left until my birthday?", "intent": "time"},
        {"id": "45", "text": "What is the exact time zone of California?", "intent": "time"},
        {"id": "46", "text": "When exactly does the next daylight saving change occur?", "intent": "time"},
        {"id": "47", "text": "What is the exact length of daylight today in my location?", "intent": "time"},
        {"id": "48", "text": "Can you remind me of the precise time for my flight tomorrow?", "intent": "time"},
        {"id": "49", "text": "What is the exact time zone of New Delhi, including any offsets?", "intent": "time"},
        {"id": "50", "text": "How many exact hours are left until 5 PM today?", "intent": "time"},
        {"id": "51", "text": "What is the precise current date and time in UTC?", "intent": "time"},
        {"id": "52", "text": "When exactly is the next full moon?", "intent": "time"},
        {"id": "53", "text": "How many exact days are left until the end of the year?", "intent": "time"},
        {"id": "54", "text": "What is the exact number of days left in this month?", "intent": "time"},
        {"id": "55", "text": "Can you give me the exact time difference between here and Brazil?", "intent": "time"},
        {"id": "56", "text": "When exactly does summer begin this year?", "intent": "time"},
        {"id": "57", "text": "How many exact days are left until next Friday?", "intent": "time"},
        {"id": "58", "text": "When precisely does winter start this year?", "intent": "time"},
        {"id": "59", "text": "How many exact hours are left until the end of the week?", "intent": "time"},
        {"id": "60", "text": "How long exactly does it take for Earth to orbit the sun?", "intent": "time"},
        {"id": "61", "text": "What is the exact number of hours in a week?", "intent": "time"},
        {"id": "62", "text": "How many exact months are left until the end of the year?", "intent": "time"},
        {"id": "63", "text": "Can you set an alarm for exactly 7 AM tomorrow?", "intent": "time"},
        {"id": "64", "text": "What is the exact time for the eclipse?", "intent": "time"},
        {"id": "65", "text": "When exactly is the next leap year?", "intent": "time"},
        {"id": "66", "text": "What is the precise time difference between New York and Beijing?", "intent": "time"},
        {"id": "67", "text": "How many exact hours are left until the next new year?", "intent": "time"},
        {"id": "68", "text": "What is the exact number of seconds in a day?", "intent": "time"},
        {"id": "69", "text": "How many exact hours have passed since midnight?", "intent": "time"},
        {"id": "70", "text": "When does the next season start exactly?", "intent": "time"},

        # Calculation Intents
        {"id": "33", "text": "What is 25 plus 30?", "intent": "calculation"},
        {"id": "34", "text": "Calculate the square root of 144.", "intent": "calculation"},
        {"id": "35", "text": "What is 15 multiplied by 6?", "intent": "calculation"},
        {"id": "36", "text": "If I have 10 apples and give away 3, how many do I have left?", "intent": "calculation"},
        {"id": "37", "text": "What is the result of 100 divided by 4?", "intent": "calculation"},
        {"id": "38", "text": "What is 72 minus 18?", "intent": "calculation"},
        {"id": "39", "text": "What is the cube root of 27?", "intent": "calculation"},
        {"id": "40", "text": "How many hours are there in 3.5 days?", "intent": "calculation"},
        {"id": "41", "text": "What is the value of 8 squared?", "intent": "calculation"},
        {"id": "42", "text": "How much is 45% of 200?", "intent": "calculation"},
        {"id": "43", "text": "If I have 15 candies and eat 7, how many are left?", "intent": "calculation"},
        {"id": "44", "text": "What’s the exact result of 250 divided by 12?", "intent": "calculation"},
        {"id": "45", "text": "How many minutes are there in 5.5 hours?", "intent": "calculation"},
        {"id": "46", "text": "What is the remainder when 17 is divided by 4?", "intent": "calculation"},
        {"id": "47", "text": "Calculate the area of a circle with a radius of 7.", "intent": "calculation"},
        {"id": "48", "text": "What is 9 to the power of 3?", "intent": "calculation"},
        {"id": "49", "text": "How many days are there in 8 weeks?", "intent": "calculation"},
        {"id": "50", "text": "What is the sum of 123 and 456?", "intent": "calculation"},
        {"id": "51", "text": "What is the exact result of 54 times 7?", "intent": "calculation"},
        {"id": "52", "text": "If I buy 5 items at $12 each, what is the total cost?", "intent": "calculation"},
        {"id": "53", "text": "How much is 15% of 350?", "intent": "calculation"},
        {"id": "54", "text": "What is the total when adding 25.75 and 34.25?", "intent": "calculation"},
        {"id": "55", "text": "What is 500 minus 127?", "intent": "calculation"},
        {"id": "56", "text": "How many centimeters are in 3 meters?", "intent": "calculation"},
        {"id": "57", "text": "How many milliliters are in 2.5 liters?", "intent": "calculation"},
        {"id": "58", "text": "What is the square of 12?", "intent": "calculation"},
        {"id": "59", "text": "What is the result of 81 divided by 9?", "intent": "calculation"},
        {"id": "60", "text": "How many seconds are in 1.5 hours?", "intent": "calculation"},
        {"id": "61", "text": "What is the exact perimeter of a square with side length 9?", "intent": "calculation"},
        {"id": "62", "text": "What is the factorial of 5?", "intent": "calculation"},
        {"id": "63", "text": "What is the total sum of 99, 100, and 101?", "intent": "calculation"},
        {"id": "64", "text": "How many weeks are there in 365 days?", "intent": "calculation"},
        {"id": "65", "text": "What is the exact division of 154 by 7?", "intent": "calculation"},
        {"id": "66", "text": "How many hours are in 2.75 days?", "intent": "calculation"},

        # Natural Conversation Intents
        {"id": "38", "text": "I love you.", "intent": "natural_conversation"},
        {"id": "39", "text": "That's great!", "intent": "natural_conversation"},
        {"id": "40", "text": "What's your favorite color?", "intent": "natural_conversation"},
        {"id": "41", "text": "Tell me something interesting.", "intent": "natural_conversation"},
        {"id": "42", "text": "How are you doing today?", "intent": "natural_conversation"},
        {"id": "43", "text": "Can you recommend a good book?", "intent": "natural_conversation"},
        {"id": "44", "text": "What do you think about technology?", "intent": "natural_conversation"},
        {"id": "45", "text": "What do you like to do for fun?", "intent": "natural_conversation"},
        {"id": "46", "text": "Do you have any hobbies?", "intent": "natural_conversation"},
        {"id": "47", "text": "What is your favorite food?", "intent": "natural_conversation"},
        {"id": "48", "text": "What's your favorite movie?", "intent": "natural_conversation"},
        {"id": "49", "text": "Tell me a joke.", "intent": "natural_conversation"},

        # Current Events Intents
        {"id": "50", "text": "What's the latest news?", "intent": "current_events"},
        {"id": "51", "text": "Tell me about today's headlines.", "intent": "current_events"},
        {"id": "52", "text": "What is happening in the world right now?", "intent": "current_events"},
        {"id": "53", "text": "Give me the latest sports updates.", "intent": "current_events"},
        {"id": "54", "text": "What's trending on social media?", "intent": "current_events"},
        {"id": "55", "text": "What are the latest political developments?", "intent": "current_events"},
        {"id": "56", "text": "Are there any updates on major world events?", "intent": "current_events"},
        {"id": "57", "text": "What's new in the world of technology?", "intent": "current_events"},
        {"id": "58", "text": "Can you provide updates on any ongoing crises?", "intent": "current_events"},
        {"id": "59", "text": "What’s the latest in entertainment news?", "intent": "current_events"},
        {"id": "60", "text": "Are there any weather alerts for today?", "intent": "current_events"},
        {"id": "61", "text": "What’s trending in global finance today?", "intent": "current_events"},
        {"id": "62", "text": "Any major breakthroughs in science today?", "intent": "current_events"},
        {"id": "63", "text": "What cultural events are happening this week?", "intent": "current_events"},
        {"id": "64", "text": "Is there any breaking news about natural disasters?", "intent": "current_events"},
        {"id": "65", "text": "What are the latest updates on COVID-19 or health news?", "intent": "current_events"},

        # weather Intents
       {"id": "67", "text": "What’s the current temperature outside?", "intent": "weather"},
       {"id": "68", "text": "Will it rain tomorrow, and if so, at what time?", "intent": "weather"},
       {"id": "69", "text": "What’s the exact weather forecast for this afternoon?", "intent": "weather"},
       {"id": "70", "text": "What is the chance of snow this weekend?", "intent": "weather"},
       {"id": "71", "text": "What’s the current humidity level in my location?", "intent": "weather"},
       {"id": "72", "text": "Will there be thunderstorms today, and at what hour?", "intent": "weather"},
       {"id": "73", "text": "What will the exact wind speed be in the next 24 hours?", "intent": "weather"},
       {"id": "74", "text": "Can you tell me the high and low temperatures for tomorrow?", "intent": "weather"},
       {"id": "75", "text": "What’s the hourly forecast for today’s weather?", "intent": "weather"},
       {"id": "76", "text": "What’s the UV index right now?", "intent": "weather"},
       {"id": "77", "text": "When exactly will the sun set today?", "intent": "weather"},
       {"id": "78", "text": "What’s the exact temperature at noon today?", "intent": "weather"},
       {"id": "79", "text": "Will it be cloudy or clear tonight?", "intent": "weather"},
       {"id": "80", "text": "What time will the rain start tomorrow?", "intent": "weather"},
       {"id": "81", "text": "Can you give me the wind speed for the next 12 hours?", "intent": "weather"},
       {"id": "82", "text": "What will the weather be like in the next 3 days?", "intent": "weather"},
       {"id": "83", "text": "Is there a heatwave expected this week?", "intent": "weather"},
       {"id": "84", "text": "What’s the exact precipitation chance for today?", "intent": "weather"},
       {"id": "85", "text": "What will the temperature be at 5 PM?", "intent": "weather"},
       {"id": "86", "text": "When exactly will the fog clear up?", "intent": "weather"},
       {"id": "87", "text": "What’s the exact dew point temperature right now?", "intent": "weather"},
       {"id": "88", "text": "Is there any chance of hail this evening?", "intent": "weather"},
       {"id": "89", "text": "Can you give me the weather forecast for the upcoming weekend?", "intent": "weather"},
       {"id": "90", "text": "What’s the exact air quality index right now?", "intent": "weather"},
       {"id": "91", "text": "Will there be strong winds tonight?", "intent": "weather"},
       {"id": "92", "text": "What’s the exact wind chill right now?", "intent": "weather"},
       {"id": "93", "text": "What will the weather be like at my location tomorrow at noon?", "intent": "weather"},
       {"id": "94", "text": "What’s the weather forecast for the next 48 hours?", "intent": "weather"},
       {"id": "95", "text": "What’s the exact visibility distance right now?", "intent": "weather"},

       # personal information intents
        {"id": "96", "text": "What do I usually do in my free time?", "intent": "personal_information"},
        {"id": "97", "text": "What are my friends' favorite activities?", "intent": "personal_information"},
        {"id": "98", "text": "Can you tell me about my family members?", "intent": "personal_information"},
        {"id": "99", "text": "What hobbies do I enjoy the most?", "intent": "personal_information"},
        {"id": "100", "text": "What do I usually talk about with my colleagues?", "intent": "personal_information"},
        {"id": "101", "text": "Where do I usually spend my vacations?", "intent": "personal_information"},
        {"id": "102", "text": "Who are the people I interact with the most?", "intent": "personal_information"},
        {"id": "103", "text": "Can you tell me where I work and what I do?", "intent": "personal_information"},
        {"id": "104", "text": "What are my goals for the future?", "intent": "personal_information"},
        {"id": "105", "text": "What kind of music do my friends and I like?", "intent": "personal_information"},
        {"id": "106", "text": "Can you remind me of important events in my life?", "intent": "personal_information"},
        {"id": "107", "text": "What is my daily routine?", "intent": "personal_information"},
        {"id": "108", "text": "Who are the people closest to me?", "intent": "personal_information"},
        {"id": "109", "text": "What type of food do I usually eat?", "intent": "personal_information"},
        {"id": "110", "text": "What do I do on weekends?", "intent": "personal_information"},
        {"id": "111", "text": "What are my favorite places to visit?", "intent": "personal_information"},
        {"id": "112", "text": "What kind of movies do my friends and I enjoy?", "intent": "personal_information"},
        {"id": "113", "text": "Who are the people I see most often?", "intent": "personal_information"},
        {"id": "114", "text": "What is my relationship with my neighbors like?", "intent": "personal_information"},
        {"id": "115", "text": "What do I enjoy talking about with family?", "intent": "personal_information"},
        {"id": "116", "text": "What events have shaped my career?", "intent": "personal_information"},
        {"id": "117", "text": "Who in my life has the most influence on me?", "intent": "personal_information"},
        {"id": "118", "text": "What do I usually discuss with my friends?", "intent": "personal_information"},
        {"id": "119", "text": "How do I usually spend time with family?", "intent": "personal_information"},
        {"id": "120", "text": "What memories do I share most with others?", "intent": "personal_information"},
        {"id": "121", "text": "Who do I consider my best friend?", "intent": "personal_information"},
        {"id": "122", "text": "What major life changes have I experienced recently?", "intent": "personal_information"},
        {"id": "123", "text": "How do I prefer to socialize with my friends?", "intent": "personal_information"},
        {"id": "124", "text": "What traditions do my family and I follow?", "intent": "personal_information"},
        {"id": "125", "text": "How do I celebrate important occasions with others?", "intent": "personal_information"},
        {"id": "126", "text": "What are my social habits with friends and family?", "intent": "personal_information"},
        {"id": "127", "text": "What are the common interests I share with others?", "intent": "personal_information"},

        # Data Of User intents
       {"id": "128", "text": "You usually enjoy reading, watching movies, and spending time outdoors in your free time.", "intent": "data of user"},
       {"id": "129", "text": "Your friends' favorite activities include playing sports, going to the gym, and exploring new restaurants.", "intent": "data of user"},
       {"id": "130", "text": "Your family members include your parents, two siblings, and your cousin who lives nearby.", "intent": "data of user"},
       {"id": "131", "text": "You enjoy hobbies like photography, hiking, and painting the most.", "intent": "data of user"},
       {"id": "132", "text": "You usually talk with your colleagues about recent work projects, travel plans, and new tech trends.", "intent": "data of user"},
       {"id": "133", "text": "You typically spend your vacations at the beach or exploring new cities.", "intent": "data of user"},
       {"id": "134", "text": "You interact the most with your close friends, family members, and a few colleagues from work.", "intent": "data of user"},
       {"id": "135", "text": "You work as a software developer at a tech company, focusing on app development.", "intent": "data of user"},
       {"id": "136", "text": "Your goals for the future include advancing your career, traveling more, and learning new skills.", "intent": "data of user"},
       {"id": "137", "text": "You and your friends like listening to pop music, indie bands, and classic rock.", "intent": "data of user"},
       {"id": "138", "text": "Some important events in your life include graduating from college, starting your first job, and moving into your own apartment.", "intent": "data of user"},
       {"id": "139", "text": "Your daily routine usually involves going to work, exercising in the evening, and spending some time relaxing with a book or show.", "intent": "data of user"},
       {"id": "140", "text": "The people closest to you include your best friend, your partner, and your parents.", "intent": "data of user"},
       {"id": "141", "text": "You usually eat healthy meals like salads, chicken, and smoothies, with the occasional treat of pizza or ice cream.", "intent": "data of user"},
       {"id": "142", "text": "On weekends, you like to hang out with friends, visit new places, or relax at home.", "intent": "data of user"},
       {"id": "143", "text": "Your favorite places to visit include local parks, museums, and cafes in the city.", "intent": "data of user"},
       {"id": "144", "text": "You and your friends enjoy watching comedies, action movies, and sometimes documentaries.", "intent": "data of user"},
       {"id": "145", "text": "You see your best friend and a few close colleagues most often during the week.", "intent": "data of user"},
       {"id": "146", "text": "Your relationship with your neighbors is friendly; you usually exchange greetings and occasionally help each other out.", "intent": "data of user"},
       {"id": "147", "text": "With your family, you enjoy talking about your childhood memories, family trips, and current events.", "intent": "data of user"},
       {"id": "148", "text": "Key events that shaped your career include finishing your degree, landing your first big project, and switching to your current role.", "intent": "data of user"},
       {"id": "149", "text": "The person who influences you the most is your mentor at work, who provides guidance and advice on your career path.", "intent": "data of user"},
       {"id": "150", "text": "You and your friends usually discuss shared interests like new movies, recent trips, and upcoming plans.", "intent": "data of user"},
       {"id": "151", "text": "You spend time with your family by having dinners together, going on trips, or just catching up over the phone.", "intent": "data of user"},
       {"id": "152", "text": "The memories you share the most with others include childhood stories, past vacations, and funny moments from work.", "intent": "data of user"},
       {"id": "153", "text": "Your best friend is someone you've known since school, and you both share similar interests and values.", "intent": "data of user"},
       {"id": "154", "text": "Recently, you've experienced changes like moving to a new city and starting a new job, which have been significant for you.", "intent": "data of user"},
       {"id": "155", "text": "You prefer to socialize with friends by going out to eat, attending events, or just catching up over coffee.", "intent": "data of user"},
       {"id": "156", "text": "Your family traditions include celebrating holidays together, having Sunday dinners, and exchanging gifts on special occasions.", "intent": "data of user"},
       {"id": "157", "text": "You celebrate important occasions like birthdays and anniversaries with close family and friends, usually with a small gathering or dinner.", "intent": "data of user"},
       {"id": "158", "text": "Your social habits include meeting up with friends once or twice a week and staying in touch regularly through messaging.", "intent": "data of user"},
       {"id": "159", "text": "Common interests you share with others include a love for traveling, watching movies, and exploring new places.", "intent": "data of user"},
]

    for data in training_data:
        db.child('training_data').child(data['id']).set(data)  # Use set with a custom ID
        print(f"Data added: {data}")

    print("All data has been added successfully.")

# Function to preprocess text
def preprocess_text(text):
    text = text.lower()
    text = re.sub(r'\d+', '', text)
    text = text.translate(str.maketrans('', '', string.punctuation))
    stop_words = set(nltk.corpus.stopwords.words('english'))
    text = ' '.join(word for word in text.split() if word not in stop_words)
    lemmatizer = nltk.WordNetLemmatizer()
    text = ' '.join(lemmatizer.lemmatize(word) for word in text.split())
    return text

# Call the function to add data (can be run only once)
add_training_data()

"""#creat objects
![image.png](data:image/png;base64,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)

##storage fire base maneger
"""

import firebase_admin
from firebase_admin import credentials as firebase_credentials, storage
from google.auth.transport.requests import Request
from google.oauth2.service_account import Credentials
import json
from datetime import timedelta

class FirebaseStorageManager:
    def __init__(self, service_account_json, bucket_name):
        """Initialize Firebase Storage with the provided credentials and bucket name."""
        self.service_account_json = service_account_json
        self.bucket_name = bucket_name
        self._initialize_firebase()

    def _initialize_firebase(self):
        """Initialize Firebase if not already initialized."""
        if not firebase_admin._apps:
            # تغيير اسم المتغير هنا لتجنب التعارض
            firebase_cred = firebase_credentials.Certificate(json.loads(self.service_account_json))
            firebase_admin.initialize_app(firebase_cred, {'storageBucket': self.bucket_name})
        self.bucket = storage.bucket()

    def generate_access_token(self):
        """Generate an access token for the service account."""
        try:
            credentials = Credentials.from_service_account_info(json.loads(self.service_account_json))
            credentials.refresh(Request())
            return credentials.token
        except Exception as e:
            print(f"Error generating access token: {e}")
            return None

    def upload_file(self, local_file_path, cloud_blob_name, expiration_days=7):
        """Upload a file and generate a signed URL for it."""
        try:
            blob = self.bucket.blob(cloud_blob_name)
            blob.upload_from_filename(local_file_path)
            print(f"File uploaded: {local_file_path} → {cloud_blob_name}")

            # Generate signed URL for accessing the file
            signed_url = blob.generate_signed_url(expiration=timedelta(days=expiration_days))
            return signed_url
        except Exception as e:
            print(f"Error uploading file: {e}")
            return None

    def download_file(self, cloud_blob_name, local_file_path):
        """Download a file from Firebase Storage to local storage."""
        try:
            blob = self.bucket.blob(cloud_blob_name)
            blob.download_to_filename(local_file_path)
            print(f"File downloaded: {cloud_blob_name} → {local_file_path}")
            return local_file_path
        except Exception as e:
            print(f"Error downloading file: {e}")
            return None

# Example Usage
if 1:
    # Initialize the Firebase Storage manager
    storage_manager = FirebaseStorageManager(json_content, "eyear-87a0e.appspot.com")

    # Upload a file and generate a signed URL
    signed_url = storage_manager.upload_file("/content/output.mp3", "audio/file.mp3")
    if signed_url:
        print(f"Generated Signed URL: {signed_url}")

    # Download a file from Firebase
    local_path = storage_manager.download_file("test_voice/latest.wav", "/content/downloaded_file.wav")
    if local_path:
        print(f"File downloaded to: {local_path}")

'''
import firebase_admin
from firebase_admin import credentials, storage
import os
import json
from IPython.display import Image, display

class FirebaseStorageUploader:
    def __init__(self, json_content, bucket_name):
        """Initialize Firebase and specify the bucket"""
        self.json_content = json_content
        self.bucket_name = bucket_name
        self._initialize_firebase()

    def _initialize_firebase(self):
        """Check initialization and initialize Firebase if not initialized"""
        if not firebase_admin._apps:
            cred = credentials.Certificate(json.loads(self.json_content))
            firebase_admin.initialize_app(cred, {
                'storageBucket': self.bucket_name
            })
        self.bucket = storage.bucket()

    def upload_image(self, image_path, destination_blob_name):
        """Upload image to Firebase"""
        try:
            blob = self.bucket.blob(destination_blob_name)
            blob.upload_from_filename(image_path)
            print(50 * "=")
            print(f"Image uploaded successfully: {image_path}")
            print(f"Image uploaded in: {destination_blob_name}")
            print(50 * "=")
        except Exception as e:
            print(f"An error occurred while uploading the image: {e}")

    def delete_local_image(self, image_name):
        """Delete the local image if it exists."""
        if os.path.exists(image_name):
            os.remove(image_name)
            print(f"Deleted the image from the local system: {image_name}")
        else:
            print(f"The image doesn't exist in the local system: {image_name}")

    def download_image(self, image_name):
        """Download image from Firebase Storage if not already downloaded."""
        self.delete_local_image(image_name)
        try:
            blob = self.bucket.blob(image_name)
            blob.download_to_filename(image_name)
            print(f"Downloaded the image: {image_name}")
            return image_name
        except Exception as e:
            print(f"An error occurred while downloading the image: {e}")
            return None

    def display_image(self, image_name):
        """Display the downloaded image."""
        try:
            return Image(image_name)
        except Exception as e:
            print(f"An error occurred while displaying the image: {e}")
            return None


# Example usage
if 1:
    bucket_name = "eyear-87a0e.appspot.com"  # Replace with your Firebase Storage bucket name

    # Initialize uploader
    uploader = FirebaseStorageUploader(json_content=json_content, bucket_name=bucket_name)

    # Download the image
    downloaded_image = uploader.download_image('image_1.jpg')
    downloaded_image = uploader.download_image('image_2.jpg')
    downloaded_image = uploader.download_image('image_3.jpg')

    # Upload an image
    uploader.upload_image('/content/image_1.jpg' , 'uploads/image_1.jpg')

    # Display the image if it was downloaded
    if downloaded_image:
        display(uploader.display_image(downloaded_image))
'''

"""##intent

###Class (for training and managing the model)
"""

'''
###Class (for training and managing the model)

# Import nltk and download required data for text processing
nltk.download('stopwords')
nltk.download('wordnet')

# Fetch training data from Firebase
def get_training_data():
    training_data = db.child('training_data').get()
    training_list = []

    if training_data.each():  # Check if there is data
        for item in training_data.each():
            if item.val() is not None:
                training_list.append(item.val())
        print("Data fetched successfully:", training_list)
    else:
        print("No data in the database.")

    return training_list if training_list else None  # Return None if the list is empty

# Fetch feedback data from Firebase
def get_feedback_data():
    feedback_data = db.child('new').child('feedback').get()
    feedback_list = []

    if feedback_data.each():  # Check if there is data
        for item in feedback_data.each():
            if item.val() is not None:
                feedback_list.append(item.val())
        print("Feedback data fetched successfully:", feedback_list)
    else:
        print("No feedback data in the database.")

    return feedback_list if feedback_list else None  # Return None if the list is empty

# Train the model
def train_model(training_list, feedback_list):
    if training_list or feedback_list:
        # Extract 'intent' from training_list and 'correct_intent' (if present) from feedback_list

        # Filter out items that are not dictionaries or lack the 'text' key
        combined_list = [item for item in (training_list + (feedback_list or [])) if isinstance(item, dict) and 'text' in item]

        texts = [preprocess_text(item['text']) for item in combined_list]
        intents = [item.get('intent', item.get('correct_intent'))  # Use get to handle missing keys
                  for item in combined_list]

        X_train, X_test, y_train, y_test = train_test_split(texts, intents, test_size=0.2, random_state=42)

        vectorizer = TfidfVectorizer()
        X_train_vectorized = vectorizer.fit_transform(X_train)

        model = RandomForestClassifier(n_estimators=100, random_state=42)
        model.fit(X_train_vectorized, y_train)

        X_test_vectorized = vectorizer.transform(X_test)
        y_pred = model.predict(X_test_vectorized)

        print(classification_report(y_test, y_pred))
        print(f"Model accuracy: {accuracy_score(y_test, y_pred)}")

        joblib.dump(model, 'trained_model.pkl')
        joblib.dump(vectorizer, 'vectorizer.pkl')

        return model, vectorizer
    else:
        print("Training list and feedback list are empty.")
        return None, None

# Train the model with training and feedback data
training_list = get_training_data()  # Fetch training data
feedback_list = get_feedback_data()  # Fetch feedback data
model, vectorizer = train_model(training_list, feedback_list)  # Train the model
'''

import nltk
# Ensure required NLTK resources are downloaded
nltk.download('stopwords')
nltk.download('wordnet')

class IntentClassifier:
    def __init__(self, db):
        self.db = db
        self.vectorizer = TfidfVectorizer()
        self.model = RandomForestClassifier(n_estimators=100, random_state=42, oob_score=True)  # Enable OOB

    def preprocess_text(self, text):
        return text.lower()

    # Fetch training data from Firebase
    def get_training_data(self):
        training_data = self.db.child('training_data').get()
        training_list = []

        if training_data.each():
            for item in training_data.each():
                if item.val() is not None:
                    training_list.append(item.val())
            print("Training data fetched successfully.")
        else:
            print("No training data in the database.")

        return training_list if training_list else None

    # Fetch feedback data from Firebase
    def get_feedback_data(self):
        feedback_data = self.db.child('new').child('feedback').get()
        feedback_list = []

        if feedback_data.each():
            for item in feedback_data.each():
                if item.val() is not None:
                    feedback_list.append(item.val())
            print("Feedback data fetched successfully.")
        else:
            print("No feedback data in the database.")

        return feedback_list if feedback_list else None

    # Train the model using training and feedback data
    def train_model(self):
        # Fetch training and feedback data
        training_data = self.get_training_data()
        feedback_data = self.get_feedback_data()

        if training_data or feedback_data:
            # Combine training and feedback data
            combined_data = [item for item in (training_data + (feedback_data or [])) if isinstance(item, dict) and 'text' in item]

            texts = [self.preprocess_text(item['text']) for item in combined_data]
            intents = [item.get('intent', item.get('correct_intent')) for item in combined_data]

            # Split data into training and testing sets
            X_train, X_test, y_train, y_test = train_test_split(texts, intents, test_size=0.2, random_state=42)

            # Vectorize text data
            X_train_vectorized = self.vectorizer.fit_transform(X_train)

            # Train the RandomForest model
            self.model.fit(X_train_vectorized, y_train)

            # Evaluate the model
            X_test_vectorized = self.vectorizer.transform(X_test)
            y_pred = self.model.predict(X_test_vectorized)

            print(classification_report(y_test, y_pred))
            print(f"Model accuracy: {accuracy_score(y_test, y_pred)}")
            print(f"OOB Score: {self.model.oob_score_}")  # Display OOB score

            # Save the trained model and vectorizer
            self.save_model()

        else:
            print("No data to train the model.")

    # Save the model and vectorizer
    def save_model(self):
        joblib.dump(self.model, 'trained_model.pkl')
        joblib.dump(self.vectorizer, 'vectorizer.pkl')
        print("Model and vectorizer saved successfully.")

    # Load a previously saved model and vectorizer
    def load_model(self):
        self.model = joblib.load('trained_model.pkl')
        self.vectorizer = joblib.load('vectorizer.pkl')
        print("Model and vectorizer loaded successfully.")

    # Collect feedback from the user and update Firebase
    def collect_feedback(self, test_text, predicted_intent, feedback_list):
        print(f"The predicted intent for '{test_text}' is: {predicted_intent}")
        feedback = "no"  # Simulate feedback (no user input)

        if feedback == 'yes':
            print("Thank you for your confirmation!")
            return True  # Return True if the answer is correct
        else:
            correct_intent = "greet"  # Simulate correct intent input

            # Add new feedback data to the "new/feedback" section in the database
            feedback_data_id = f"feedback_{len(feedback_list) + 1}" if feedback_list else "feedback_1"
            self.db.child('new').child('feedback').child(feedback_data_id).set({
                "text": test_text,
                "predicted_intent": predicted_intent,
                "correct_intent": correct_intent
            })
            print("Thank you for your feedback! The new data has been added to 'new/feedback'.")

            # Add the corrected feedback to the training data for future training
            training_list = self.get_training_data()  # Fetch current training data
            training_data_id = f"new_training_{len(training_list) + 1}"
            self.db.child('training_data').child(training_data_id).set({
                "text": test_text,
                "intent": correct_intent
            })
            print("The corrected data has been added to 'training_data'.")
            return False  # Return False if the answer is incorrect

    # Test the model and collect feedback
    def test_model(self):
        feedback_list = self.get_feedback_data()  # Fetch existing feedback data
        test_sentences = ["what is my name"]  # Example test sentences, replace with actual input

        for test_text in test_sentences:
            # Vectorize the input text
            test_vector = self.vectorizer.transform([test_text])

            # Make prediction
            predicted_intent = self.model.predict(test_vector)[0]

            # Collect feedback on the prediction
            self.collect_feedback(test_text, predicted_intent, feedback_list)

# Function to use the trained model for predictions
def intent(model, vectorizer, user_input):
    if user_input.lower() == 'exit':
        print("Exiting the program.")
        return  # Exit the function if the user wants to exit

    preprocessed_input = user_input.lower()

    # Define predict_intent function within use_model
    def predict_intent(model, vectorizer, text):
        """Predicts the intent of a given text using the trained model and vectorizer."""
        input_vector = vectorizer.transform([text])
        predicted_intent = model.predict(input_vector)[0]
        return predicted_intent

    predicted_intent = predict_intent(model, vectorizer, preprocessed_input)  # Call the newly defined function
    print(f"The predicted intent for '{user_input}' is: {predicted_intent}")

    # Save the intent in a variable
    intent_var = predicted_intent
    print(f"Saved intent: {intent_var}")

    return intent_var

# Example usage
if __name__ == "__main__":
    # Instantiate the IntentClassifier
    classifier = IntentClassifier(db)

    # Train the model with data from Firebase
    classifier.train_model()

    # Test the model and collect feedback
    classifier.test_model()

    # Optionally save the model and vectorizer after training
    classifier.save_model()  # If not already saved during training

    # Load the model if needed
    # classifier.load_model()  # Uncomment this to load a previously saved model

    # Use the model for prediction
    user_input = "hello"
    prdect_intent = intent(classifier.model, classifier.vectorizer, user_input)  # Use the trained model and vectorizer for the given input
    print(f"Predicted Intent: {prdect_intent}")

"""##enhance image"""

class ImageEnhancer:
    """Class to handle image enhancement and processing tasks."""

    def __init__(self, image_files=None):
        """Initializes with a list of image paths."""
        self.image_files = image_files if image_files else []

    def enhance_image(self, image):
        """Enhances the image by reducing blur, improving sharpness, and adjusting contrast."""
        if image is None:
            print("Error: No image to process.")
            return None

        # Apply a bilateral filter to reduce noise while preserving edges
        filtered_image = cv2.bilateralFilter(image, 9, 75, 75)

        # Enhance sharpness using unsharp masking
        blurred_image = cv2.GaussianBlur(filtered_image, (0, 0), 3)
        sharpened_image = cv2.addWeighted(filtered_image, 1.5, blurred_image, -0.5, 0)

        # Apply adaptive histogram equalization for better contrast
        lab = cv2.cvtColor(sharpened_image, cv2.COLOR_BGR2LAB)
        l, a, b = cv2.split(lab)
        l = cv2.equalizeHist(l)
        lab = cv2.merge([l, a, b])
        enhanced_image = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)

        return enhanced_image

    def remove_reflection(self, image):
        """Try to reduce reflections using edge detection and inpainting."""
        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

        # Use Canny edge detection to find strong edges that could be reflections
        edges = cv2.Canny(gray_image, 50, 150)

        # Inpaint the edges to reduce reflections (you may need to fine-tune this)
        inpainted_image = cv2.inpaint(image, edges, 3, cv2.INPAINT_TELEA)

        return inpainted_image

    def process_and_combine_images(self):
        """Processes multiple images, enhances them, and combines them into one."""
        enhanced_images = []

        for image_path in self.image_files:
            # Load the image
            image = cv2.imread(image_path)
            if image is None:
                print(f"Error: Could not load image from {image_path}")
                continue

            # Remove reflections (optional)
            image_without_reflection = self.remove_reflection(image)

            # Enhance the image
            enhanced_image = self.enhance_image(image_without_reflection)
            if enhanced_image is not None:
                # Resize the image to ensure all images have the same dimensions
                resized_image = cv2.resize(enhanced_image, (640, 480))  # Resize to 640x480 for consistency
                enhanced_images.append(resized_image)

        # Combine images using the mean function
        if enhanced_images:
            combined_image = np.mean(enhanced_images, axis=0).astype(np.uint8)
            return combined_image
        else:
            print("No images to combine.")
            return None

    def enhance_and_save_image(self, image_path, output_path='enhanced_image.jpg'):
        """Enhances the image and saves it."""
        try:
            # Load the image using OpenCV
            image = cv2.imread(image_path)
            if image is None:
                print(f"Error: Could not load image from {image_path}")
                return

            # Remove reflections (optional)
            image_without_reflection = self.remove_reflection(image)

            # Enhance the image
            enhanced_image = self.enhance_image(image_without_reflection)

            # Save the enhanced image
            if enhanced_image is not None:
                cv2.imwrite(output_path, enhanced_image)
                print(f"Image enhanced and saved as '{output_path}'")
            else:
                print("Error: Image enhancement failed.")
        except Exception as e:
            print(f"An error occurred during image enhancement: {e}")

# Example usage
if run_example_usage:
    # List of image file paths (replace with actual paths)
    image_paths = [
        'image_1.jpg',
        'image_2.jpg',
        'image_3.jpg'
    ]

    # Initialize the ImageEnhancer with the image paths
    enhancer = ImageEnhancer(image_paths)

    # Process and combine images
    combined_image = enhancer.process_and_combine_images()
    if combined_image is not None:
        # Save the combined image
        cv2.imwrite('combined_image.jpg', combined_image)
        print("Combined image saved as 'combined_image.jpg'")
    # Enhance the compined image
        enhancer.enhance_and_save_image('combined_image.jpg', 'enhanced_combined_image.jpg')

    # Enhance and save a single image
    enhancer.enhance_and_save_image('image_1.jpg', 'enhanced_image_1.jpg')

"""##image caption"""

from PIL import Image  # Ensure correct import

class ImageCaptionGenerator:
    def __init__(self, model_name="Salesforce/blip-image-captioning-base"):
        # تحميل النماذج
        self.processor = BlipProcessor.from_pretrained(model_name)
        self.model = BlipForConditionalGeneration.from_pretrained(model_name).to("cuda" if torch.cuda.is_available() else "cpu")

    def predict_caption(self, image_path):
        # فتح الصورة
        image = Image.open(image_path).convert('RGB')

        # تجهيز المدخلات
        inputs = self.processor(image, return_tensors="pt").to("cuda" if torch.cuda.is_available() else "cpu")

        # توليد الوصف
        output = self.model.generate(**inputs)
        caption = self.processor.decode(output[0], skip_special_tokens=True)

        return caption

if run_example_usage:
    # تجربة الكود
    image_caption_generator = ImageCaptionGenerator()
    image_path = "/content/enhanced_combined_image.jpg"  # ضع مسار الصورة هنا
    caption = image_caption_generator.predict_caption(image_path)
    print(f"Generated Caption: {caption}")



# Import libraries
import torch
from PIL import Image
import numpy as np
import cv2
from transformers import DetrImageProcessor, DetrForObjectDetection, BlipProcessor, BlipForQuestionAnswering

# Load YOLOv5 model
model_yolo = torch.hub.load('ultralytics/yolov5', 'yolov5s')  # Load YOLOv5s (small version) model

class EnhancedImageProcessor:
    def __init__(self, image_path):
        self.image_path = image_path

        # Load DETR model and processor
        self.processor_detr = DetrImageProcessor.from_pretrained("facebook/detr-resnet-50")
        self.model_detr = DetrForObjectDetection.from_pretrained("facebook/detr-resnet-50")

        # Load BLIP model and processor for question-answering
        self.processor_blip = BlipProcessor.from_pretrained("Salesforce/blip-vqa-base")
        self.model_blip = BlipForQuestionAnswering.from_pretrained("Salesforce/blip-vqa-base")

        # Assign YOLOv5 model loaded from PyTorch Hub
        self.yolo = model_yolo

    def detect_objects_with_yolo(self):
        # Perform object detection using YOLOv5 on the input image
        results = self.yolo(self.image_path)
        results_df = results.pandas().xyxy[0]  # Get results as pandas DataFrame
        detected_objects = results_df[['name', 'xmin', 'ymin', 'xmax', 'ymax']].to_dict(orient="records")
        return detected_objects

    def detect_objects_with_detr(self):
        image = Image.open(self.image_path)
        inputs = self.processor_detr(images=image, return_tensors="pt")
        outputs = self.model_detr(**inputs)
        target_sizes = torch.tensor([image.size[::-1]])
        results = self.processor_detr.post_process_object_detection(outputs, target_sizes=target_sizes, threshold=0.8)[0]
        detected_objects = [{'label': label, 'box': box} for label, box in zip(results['labels'], results['boxes'])]
        return detected_objects

    def answer_question(self, question):
        image = Image.open(self.image_path)
        inputs = self.processor_blip(images=image, text=question, return_tensors="pt")
        outputs = self.model_blip.generate(**inputs)
        answer = self.processor_blip.decode(outputs[0], skip_special_tokens=True)
        return answer
'''
# Test the EnhancedImageProcessor class
# Upload an image to Colab or use an existing image path
image_path = "/content/enhanced_combined_image.jpg"  # Replace with your image path in Colab
processor = EnhancedImageProcessor(image_path)

# Detect objects with YOLOv5
yolo_objects = processor.detect_objects_with_yolo()
print("YOLOv5 detected objects:", yolo_objects)

# Detect objects with DETR
detr_objects = processor.detect_objects_with_detr()
print("DETR detected objects:", detr_objects)

# Example question-answering with BLIP
questions = [
    "How many people are in the image?",
    "What is the main object in the image?",
    "What colors are in the image?",
    "Is there a person in the image?",
    "Where is the car located in the image?",
    "What activity is happening in the image?"
]

for question in questions:
    answer = processor.answer_question(question)
    print(f"Q: {question}\nA: {answer}\n")
'''

"""##text_to_speech

"""

class TextToSpeechConverter:
    def __init__(self, text, lang='en'):
        self.text = text
        self.lang = lang
        self.mp3_path = "/content/output.mp3"
        self.wav_path = "/content/output.wav"

    def convert_to_mp3(self):
        """Convert the text to speech and save it as an MP3 file."""
        tts = gTTS(self.text, lang=self.lang)
        tts.save(self.mp3_path)
        print(f"MP3 file saved at {self.mp3_path}")

    def convert_mp3_to_wav(self):
        """Convert the saved MP3 file to WAV format."""
        sound = AudioSegment.from_mp3(self.mp3_path)
        sound.export(self.wav_path, format="wav")
        print(f"WAV file saved at {self.wav_path}")

    def process(self):
        """Convert text to MP3 and then to WAV."""
        self.convert_to_mp3()
        self.convert_mp3_to_wav()

# The code inside this block will only execute when the script is run directly
if run_example_usage:
    text = "Hello, welcome to the world of programming!"
    lang = 'en'  # Language code, Arabic in this case

    # Create an instance of the TextToSpeechConverter class
    converter = TextToSpeechConverter(text, lang)

    # Call the process method to generate the speech
    converter.process()

"""##voice recognation"""


from pydub import AudioSegment
import speech_recognition as sr

class AudioProcessor:
    def __init__(self, mp3_file):
        self.mp3_file = mp3_file
        self.wav_file = mp3_file.replace(".mp3", ".wav")

    def convert_to_wav(self):
        try:
            # Load the MP3 file
            audio = AudioSegment.from_file(self.mp3_file)

            # Export the audio as WAV
            audio.export(self.wav_file, format="wav")
            print(f"Conversion successful! File saved as {self.wav_file}")
        except Exception as e:
            print(f"Error during conversion: {e}")

    def transcribe_audio(self):
        """Transcribe audio from WAV file to text."""
        recognizer = sr.Recognizer()
        try:
            with sr.AudioFile(self.wav_file) as source:
                audio_data = recognizer.record(source)
                text = recognizer.recognize_google(audio_data)
            return text
        except sr.UnknownValueError:
            return "Google Speech Recognition could not understand the audio."
        except sr.RequestError as e:
            return f"Could not request results from Google Speech Recognition service; {e}"

    def process_audio(self):
        """Convert MP3 to WAV and transcribe the audio."""
        self.convert_to_wav()  # Convert the MP3 to WAV
        text = self.transcribe_audio()  # Transcribe the WAV audio
        return text


# Example usage:
if run_example_usage:
    mp3_file = "/content/downloaded_file.wav"  # Update with your actual MP3 file path
    audio_processor = AudioProcessor(mp3_file)
    transcription = audio_processor.process_audio()
    print(f"Transcription for {mp3_file}:\n{transcription}")

'''
!pip install python-magic
import magic

def detect_file_type(file_path):
    # Create a magic object to detect file type
    file_type = magic.Magic()
    # Get the file type based on the file content
    file_type_info = file_type.from_file(file_path)
    return file_type_info

# Example usage
file_path = '/content/output.mp3'
file_type = detect_file_type(file_path)
print(f"The file type is: {file_type}")
'''

"""##OCR"""

class ImageTextExtractor:
    def __init__(self, image_path):
        self.image_path = image_path

    def extract_text_from_image(self):
        """Extract text from an image using pytesseract."""
        try:
            # Open the image from the path
            image = Image.open(self.image_path)

            # Extract text using pytesseract
            extracted_text = pytesseract.image_to_string(image)

            # Display the extracted text
            print("Extracted text:")
            print(extracted_text)

            return extracted_text

        except Exception as e:
            print(f"An error occurred while processing the image: {e}")
            return None


if run_example_usage:
    image_path = "/content/drive/MyDrive/_eyEar_/process_data/ocr.jpeg"  # Update with your actual image path
    extractor = ImageTextExtractor(image_path)
    extracted_text = extractor.extract_text_from_image()

"""##Mini feauture"""

class TimeZoneHandler:
    """
    Class to handle time and date in different timezones with formatting options.
    """
    def __init__(self, timezone: str):
        self.timezone = timezone
        self.tz = pytz.timezone(self.timezone)

    def get_current_time(self):
        """Get the current time in the specified timezone in 24-hour format."""
        now = datetime.now(self.tz)
        return now.strftime("%H:%M:%S")

    def get_current_date(self):
        """Get the current date in the specified timezone in YYYY-MM-DD format."""
        now = datetime.now(self.tz)
        return now.strftime("%Y-%m-%d")

    def get_current_time_in_12hr_format(self):
        """Get the current time in 12-hour format with AM/PM."""
        now = datetime.now(self.tz)
        return now.strftime("%I:%M:%S %p")

    def get_current_date_in_full(self):
        """Get the full date format like 'Monday, November 10, 2024'."""
        now = datetime.now(self.tz)
        return now.strftime("%A, %B %d, %Y")

    def get_current_time_and_date(self):
        """Get the current time and date in the specified timezone."""
        return f"The current time in {self.timezone} is {self.get_current_time()} and the date is {self.get_current_date()}."

    def get_current_time_and_date_full(self):
        """Get the current time and date in full format."""
        return f"The current time in {self.timezone} is {self.get_current_time_in_12hr_format()} and the full date is {self.get_current_date_in_full()}."

# Example usage:
if run_example_usage:
    timezone = 'Africa/Cairo'  # Change this to any valid timezone

    try:
        # Create a TimeZoneHandler object with the chosen timezone
        time_zone_handler = TimeZoneHandler(timezone)

        # Output current time and date
        print(time_zone_handler.get_current_time_and_date())

        # Show time and date in advanced formats
        print("\nAdvanced Time Formats:")
        print("12-hour format:", time_zone_handler.get_current_time_in_12hr_format())
        print("Full date format:", time_zone_handler.get_current_date_in_full())

    except pytz.UnknownTimeZoneError:
        print("Error: The timezone provided is invalid. Please enter a valid timezone.")

class MathEvaluator:
    def __init__(self):
        # Initialize with possible operators and operations
        self.operators = ["+", "-", "*", "/"]
        self.word_map = {
            "plus": "+",
            "minus": "-",
            "times": "*",
            "divided by": "/"
        }

    def calculate(self, expression):
        """Performs basic arithmetic calculations."""
        # Allow only numbers and arithmetic operators
        if not re.match(r'^[0-9+\-*/\s]+$', expression):
            return "Invalid expression. Please use numbers and operators only."
        try:
            # Evaluate the mathematical expression safely
            result = eval(expression, {"__builtins__": None}, {})
            return f"The result is: {result}"
        except Exception as e:
            return f"I couldn't perform the calculation. Please check your expression. Error: {str(e)}"

    def evaluate_math_expression(self, user_input):
        """Converts words into arithmetic expressions and calculates the result."""
        # Convert user input to lowercase
        user_input = user_input.lower()

        # Replace word equivalents with symbols
        for word, symbol in self.word_map.items():
            user_input = user_input.replace(word, symbol)

        # Split into individual words and convert words to numbers where possible
        words = user_input.split()
        for i, word in enumerate(words):
            try:
                words[i] = str(w2n.word_to_num(word))  # Convert word to number
            except ValueError:
                continue  # Ignore words that can't be converted

        # Join the words back into an expression
        expression = " ".join(words)
        return self.calculate(expression)

    def is_calculation_request(self, user_input):
        """Checks if the user input contains a valid mathematical expression."""
        # Check if the input contains mathematical operators or their word equivalents
        return any(op in user_input for op in self.operators) or any(word in user_input for word in self.word_map)

    def user_guidance(self):
        """Provides guidance on how to use the math evaluator."""
        return ("To use this calculator, you can enter an arithmetic expression like:\n"
                "- 2 + 3\n"
                "- 4 times 5\n"
                "- 10 divided by 2\n"
                "Supported operators are: plus, minus, times, divided by, +, -, *, /.")

if run_example_usage:
    evaluator = MathEvaluator()

    # Predefined variable (user_input) for testing
    user_input = "four plus five"  # Change this to any math expression you want to test

    print("Welcome to the Math Evaluator!")
    print(evaluator.user_guidance())  # Display user guidance on how to use the calculator

    if evaluator.is_calculation_request(user_input):
        result = evaluator.evaluate_math_expression(user_input)
        print(result)
    else:
        print("Invalid input. Please try again.")
        print("For assistance, refer to the guidance above.")

"""##BOT"""

import torch
from transformers import AutoTokenizer, AutoModelForCausalLM
'''
class ChatBot:
    def __init__(self, model_name="meta-llama/Llama-3.2-1B-Instruct", token="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"):
        """
        Initializes the ChatBot with a specific model and authentication token.
        """
        self.token = token
        self.model_name = model_name
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

        # Load tokenizer and model with authentication token
        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name, use_auth_token=self.token)
        self.model = AutoModelForCausalLM.from_pretrained(self.model_name, use_auth_token=self.token).to(self.device)

    def generate_response(self, user_message, max_length=30, temperature=0.7, top_p=0.9):
        """
        Generates a short, concise response from the model.
        """
        # Convert user message to tokens
        inputs = self.tokenizer.encode(user_message, return_tensors='pt').to(self.device)

        # Disable gradients (we are only generating the response)
        with torch.no_grad():
            # Generate the response
            outputs = self.model.generate(
                inputs,
                max_length=max_length,  # Limit the length of the response
                num_return_sequences=1,  # Number of responses to generate
                pad_token_id=self.tokenizer.eos_token_id,  # Padding token
                temperature=temperature,  # Creativity of the response
                top_p=top_p  # Diversity in the response
            )

        # Return the response as a readable string
        return self.tokenizer.decode(outputs[0], skip_special_tokens=True)

    def start_chat(self, message):
        """
        Starts the chat interaction with an AI assistant response style.
        """
        print("Hello! I'm your AI Assistant. How can I assist you today?")
        print("To end the chat, type 'exit' or 'quit'.")

        # Check if the user wants to exit the conversation
        if message.lower() in ["exit", "quit"]:
            print("AI Assistant: Goodbye! I'm here if you need help again.")

        # Generate and print the AI Assistant's response
        response = self.generate_response(message)
        print(f"You: {message}")
        print(f"AI Assistant: {response}")
        return response

if run_example_usage:
    # Create an instance of ChatBot
    bot = ChatBot()

    # Define a message to simulate interaction
    message = "What is AI?"

    # Generate and print the AI Assistant's response
    response = bot.start_chat(message)
    print(response)

    # حذف الكائن `bot`
    del bot

    # استدعاء جمع القمامة لتحرير الذاكرة
    gc.collect()
    '''

import torch
from transformers import AutoTokenizer, AutoModelForCausalLM
import pyrebase
from datetime import datetime
import gc

# Firebase configuration - Replace these with your Firebase project credentials
config = {
    'apiKey': "AIzaSyCBvKO1K2FJ_MoPXAckuga40mwG593Qo7o",
    'authDomain': "eyear-87a0e.firebaseapp.com",
    'databaseURL': "https://eyear-87a0e-default-rtdb.firebaseio.com",
    'projectId': "eyear-87a0e",
    'storageBucket': "eyear-87a0e.appspot.com",
    'messagingSenderId': "337767300301",
    'appId': "1:337767300301:web:050cb7adf9c7d0e3b8bd84",
    'measurementId': "G-8SRQ7WFTPK"
}

# Initialize Firebase
firebase = pyrebase.initialize_app(config)
db = firebase.database()  # Using Realtime Database
print("Firebase initialized successfully.")

class ChatBot:
    def __init__(self, model_name="meta-llama/Llama-3.2-1B-Instruct", token="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"):
        """
        Initializes the ChatBot with a specific model and authentication token.
        """
        self.token = token
        self.model_name = model_name
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

        # Load tokenizer and model with authentication token
        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name, use_auth_token=self.token)
        self.model = AutoModelForCausalLM.from_pretrained(self.model_name, use_auth_token=self.token).to(self.device)

    def generate_response(self, user_message, user_id, max_length=30, temperature=0.1, top_p=0.9):
        """
        Generates a short, concise response from the model, ensuring relevance to the eyEar project and prevents repeated responses.
        """
        # Retrieve user data (name, age) and project info from Firebase if available
        user_data = self.get_user_profile(user_id)
        name = user_data.get("name", "User")
        age = user_data.get("age", "Unknown")

        # Retrieve project information from Firebase
        project_info = self.get_project_info()
        project_description = project_info.get("description", "No description available.")
        project_status = project_info.get("status", "Unknown")

        # Keep track of last response to avoid repetition
        if hasattr(self, 'last_response') and self.last_response == user_message:
            return "I noticed you asked that already! How can I help you with something else?"

        # Update the last response
        self.last_response = user_message

        # Personalize response based on collected data
        if "name" in user_message.lower():
            return f"Your name is {name}, right?"
        elif "age" in user_message.lower():
            return f"You mentioned you're {age} years old, correct?"

        # Handle commands to update user profile (e.g., "my name is X" or "my age is Y")
        if "my name is" in user_message.lower():
            new_name = user_message.split("my name is")[-1].strip()
            self.set_user_profile(user_id, name=new_name)
            return f"Got it! Your name is now {new_name}."

        if "my age is" in user_message.lower():
            new_age = user_message.split("my age is")[-1].strip()
            self.set_user_profile(user_id, age=new_age)
            return f"Got it! Your age is now {new_age}."

        # Provide information about the project (eyear)
        if 'eyear' in user_message.lower() or 'project' in user_message.lower():
            return f"The eyEar project is: {project_description}\nStatus: {project_status}"

        # Convert user message to tokens
        inputs = self.tokenizer.encode(user_message, return_tensors='pt').to(self.device)

        # Disable gradients (we are only generating the response)
        with torch.no_grad():
            # Generate the response with specified temperature and top_p values
            outputs = self.model.generate(
                inputs,
                max_length=max_length,  # Limit the length of the response
                num_return_sequences=1,  # Number of responses to generate
                pad_token_id=self.tokenizer.eos_token_id,  # Padding token
                temperature=temperature,  # Creativity of the response
                top_p=top_p  # Diversity in the response
            )

        # Return the response as a readable string
        response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
        return response

    def start_chat(self, message, user_id):
        """
        Starts the chat interaction with an AI assistant response style.
        """
        # Check if the user wants to exit the conversation
        if message.lower() in ["exit", "quit"]:
            print("AI Assistant: Goodbye! I'm here if you need help again.")
            return False

        # Generate and print the AI Assistant's response
        response = self.generate_response(message, user_id)

        # Log the conversation to Firebase
        self.save_to_firebase(message, response, user_id)

        print(f"You: {message}")
        print(f"AI Assistant: {response}")
        return response

    def save_to_firebase(self, user_message, bot_response, user_id):
        """
        Save the conversation history in Firebase under the user's profile.
        """
        timestamp = datetime.now().strftime("%Y-%m-%dT%H-%M-%S-%f")  # Unique timestamp

        # Prepare the data structure for saving the conversation
        data = {
            "user_message": user_message,
            "bot_response": bot_response,
            "timestamp": timestamp
        }

        # Save the conversation to the user's history
        db.child("users").child(user_id).child("conversation_history").child(timestamp).set(data)
        print(f"Conversation history saved to Firebase under user '{user_id}'.")

    def get_user_profile(self, user_id):
        """
        Retrieve the user's profile from Firebase (name, age, etc.)
        """
        user_profile = db.child("users").child(user_id).get()
        if user_profile.each():
            # Return user data if available, else return default values
            return user_profile.val()
        else:
            # Return default data if no profile exists
            return {"name": "User", "age": "Unknown"}

    def set_user_profile(self, user_id, name=None, age=None):
        """
        Set the user's profile (name, age, etc.) in Firebase.
        """
        user_profile = {}
        if name:
            user_profile["name"] = name
        if age:
            user_profile["age"] = age

        # Save profile data to Firebase
        db.child("users").child(user_id).update(user_profile)
        print(f"User profile updated for '{user_id}'.")

    def get_project_info(self):
        """
        Retrieve the project information from Firebase (eyear details).
        """
        project_info = db.child("project_info").child("eyear").get()
        if project_info.each():
            # Return project data if available, else return default values
            return project_info.val()
        else:
            # Return default data if no project info exists
            return {"description": "No description available.", "status": "Unknown"}

    def set_project_info(self, description=None, status=None):
        """
        Set the project information (eyear details) in Firebase.
        """
        project_info = {}
        if description:
            project_info["description"] = description
        if status:
            project_info["status"] = status

        # Save project data to Firebase
        db.child("project_info").child("eyear").update(project_info)
        print("Project information updated.")

# Example Usage - Dynamic interaction
if 0:
    # Initialize the bot
    bot = ChatBot()

    user_id = "ahmed_said"  # This could be a dynamic value or fetched from the user login

    # Set user's profile (name, age) if not set
    bot.set_user_profile(user_id, name="Ahmed", age="17")

    # Set project info (eyear) if not set
    bot.set_project_info(description="eyEar is a smart device for the visually impaired that helps them navigate their surroundings using image analysis.", status="In development")

    # Start chatting
    output =  bot.start_chat("hello", user_id)
    print(output)

    # Clean up objects
    objects_to_delete = ["bot"]

    # Delete the objects if they exist
    for obj_name in objects_to_delete:
        try:
            del globals()[obj_name]
        except KeyError:
            print(f"{obj_name} object was already deleted or not defined.")

    # Call garbage collector
    freed_objects = gc.collect()

    print(f"Garbage collector freed {freed_objects} unreachable objects.")



"""##general knowledge"""

class QuestionAnsweringBot:
    def __init__(self, model_name="meta-llama/Llama-3.2-1B-Instruct", token="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"):
        """Initialize the bot with a specific model and authentication token."""
        self.token = token
        self.model_name = model_name
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.qa_model = pipeline("question-answering")

    def extract_keywords(self, question):
        """Extract keywords from the question."""
        return re.findall(r'\w+', question)

    def fetch_wikipedia_content(self, topic):
        """Fetch the first paragraph of the Wikipedia page for the topic."""
        url = f"https://en.wikipedia.org/w/api.php?action=query&format=json&prop=extracts&exintro=&explaintext=&titles={topic}"
        try:
            response = requests.get(url)
            response.raise_for_status()
            data = response.json()
            page = next(iter(data['query']['pages'].values()))
            extract = page.get('extract', "")
            if extract:
                return extract.strip()
            else:
                print(f"No extract found for topic: {topic}")
                return ""
        except requests.RequestException as e:
            print(f"Request error while fetching Wikipedia content: {e}")
            return ""

    def search_duckduckgo(self, query):
        """Search DuckDuckGo and return result URLs and snippets."""
        query = query.replace(' ', '+')
        url = f"https://duckduckgo.com/html/?q={query}"
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36"
        }

        try:
            response = requests.get(url, headers=headers)
            response.raise_for_status()
            soup = BeautifulSoup(response.text, 'html.parser')
            results = []
            for item in soup.find_all('a', class_='result__a'):
                title = item.get_text()
                link = item['href']
                results.append({'title': title, 'link': link})
            return results
        except requests.RequestException as e:
            print(f"Error while searching DuckDuckGo: {e}")
            return []

    def handle_fallback(self, topic):
        """Fallback if both content fetch methods fail."""
        return f"No sufficient information found for '{topic}'. Please check the topic or try again."

    def provide_first_level_answer(self, question, context):
        """Generate a basic answer for the question based on the provided context."""
        qa_result = self.qa_model(question=question, context=context)
        if qa_result['answer']:
            return qa_result['answer']
        else:
            return "No specific answer found."

    def provide_second_level_info(self, topic):
        """Provide summarized information based on the topic."""
        content = self.fetch_wikipedia_content(topic)
        if content:
            summarized_info = content.split('.')[0].strip() + '.'
            return f"Summarized information about {topic}:\n{summarized_info}\n"
        else:
            return f"No additional information found for {topic}."

    def provide_third_level_info(self, topic):
        """Provide detailed information based on the topic."""
        content = self.fetch_wikipedia_content(topic)
        if content:
            return f"Further detailed information about {topic}:\n{content}\n"
        else:
            return f"No additional information found for {topic}."

    def answer_question(self, question, info_level):
        """Main method to answer a user's question based on information level."""
        start_time = time.time()  # Start time measurement

        print(f"\nAnalyzing question: {question}")

        # Improve the question
        improved_question = question.strip()
        print(f"Improved question: {improved_question}")

        # Extract keywords from the question
        keywords = self.extract_keywords(improved_question)
        print(f"Extracted keywords: {keywords}")

        # Extract the topic from the question
        topic = keywords[-1] if keywords else "unknown"
        print(f"Extracted topic: {topic}")

        # Fetch Wikipedia content for the topic
        print(f"Fetching Wikipedia content for topic: {topic}")
        wikipedia_content = self.fetch_wikipedia_content(topic)
        print(f"Fetched Wikipedia content length: {len(wikipedia_content)} characters")

        # If no Wikipedia content found, use DuckDuckGo
        if not wikipedia_content:
            print("No sufficient content found. Retrying with DuckDuckGo search.")
            search_results = self.search_duckduckgo(topic)

            if not search_results:
                print("No results from DuckDuckGo. Executing fallback logic.")
                answer = self.handle_fallback(topic)
                print(f"Answer: {answer}")
                end_time = time.time()  # End time measurement
                print(f"Time taken: {end_time - start_time:.2f} seconds")
                return answer
            else:
                print(f"Found {len(search_results)} results from DuckDuckGo.")
                context = " ".join(result['title'] for result in search_results)
        else:
            context = wikipedia_content

        # Generate answer based on information level
        if info_level == "first":
            answer = self.provide_first_level_answer(improved_question, context)
        elif info_level == "second":
            answer = self.provide_second_level_info(topic)
        elif info_level == "third":
            answer = self.provide_third_level_info(topic)
        else:
            answer = "Invalid information level requested."

        end_time = time.time()  # End time measurement
        print(answer)
        print(f"Time taken: {end_time - start_time:.2f} seconds")
        return answer

# Example usage
if run_example_usage:
    # Instantiate the bot
    bot = QuestionAnsweringBot()

    # Test cases
    test_questions = [
        ("Where is Cairo?", "first"),
        ("What is the capital of France?", "second"),
        ("Who invented the telephone?", "third"),
        ("What is quantum computing?", "first"),
        ("Explain the theory of relativity.", "second")
    ]

    # Process each test case and print runtime
    for question, info_level in test_questions:
        answer = bot.answer_question(question, info_level)
        print(f"Answer: {answer}")
   # Example usage
    bot = QuestionAnsweringBot()
    print(20*"=","\n" , "answer : " , bot.answer_question("what is ai", "third"))

"""#main

##main code
"""

import gc
import pyrebase
import os

# Firebase configuration
config = {
  'apiKey': "AIzaSyCBvKO1K2FJ_MoPXAckuga40mwG593Qo7o",
  'authDomain': "eyear-87a0e.firebaseapp.com",
  'databaseURL': "https://eyear-87a0e-default-rtdb.firebaseio.com",
  'projectId': "eyear-87a0e",
  'storageBucket': "eyear-87a0e.appspot.com",
  'messagingSenderId': "337767300301",
  'appId': "1:337767300301:web:050cb7adf9c7d0e3b8bd84",
  'measurementId': "G-8SRQ7WFTPK"
}

# Initialize Firebase using pyrebase
firebase = pyrebase.initialize_app(config)
db = firebase.database()  # Using Realtime Database

print("Firebase initialized successfully.")

# Function to clean up objects and free memory
def cleanup():
    """Clean up objects and free memory."""
    objects_to_delete = [
        "image_caption_generator", "llama_bot", "search_bot",
        "storage_manager", "time_zone_handler", "classifier"
    ]
    for obj_name in objects_to_delete:
        try:
            del globals()[obj_name]
        except KeyError:
            print(f"{obj_name} object was already deleted or not defined.")
    freed_objects = gc.collect()
    print(f"Garbage collector freed {freed_objects} unreachable objects.")

def main_loop():
    # Initialize Firebase with pyrebase
    db_ref = firebase.database()  # Using Realtime Database

    print("Firebase initialized successfully.")

    # Set initial `/run/` value to True
    db_ref.child("/run/").set(True)

    # Variable to track the loop state
    is_running = True

    # Initialize necessary components (example, replace with actual initialization)
    bucket_name = "eyear-87a0e.appspot.com"
    timezone = 'Africa/Cairo'
    llama_bot = ChatBot() # make answer usind llama 1B model
    search_bot = QuestionAnsweringBot() # make answer using searh on wepsite
    storage_manager = FirebaseStorageManager(json_content, "eyear-87a0e.appspot.com") # Firebase Storage manegeer
    time_zone_handler = TimeZoneHandler(timezone) # time_zone
    classifier = IntentClassifier(db)  # Instantiate the IntentClassifier
    image_caption_generator = ImageCaptionGenerator()

    print("Starting main loop. Update '/run/' to False to stop.")

    first_audio_repetition = 0

    # Main loop
    while is_running:

        run = db.child("run").get().val()  # Get the actual value from Firebase (assuming you're using Firebase SDK)
        if run != True:
            cleanup()
            break

        audui = db.child("voice/type").get().val()  # Get the actual value from Firebase (assuming you're using Firebase SDK)
        if audui != True:
            if first_audio_repetition < 1 :
                print("Restarting the loop...")  # رسالة توضح إعادة التشغيل
                first_audio_repetition += 1

            continue  # إعادة الحلقة إلى البداية


        # Download data
        downloaded_audio = storage_manager.download_file("voice/latest.wav", "audio.mp3")

        #Transcription audio
        mp3_file = "audio.mp3"  # MP3 file path
        audio_processor = AudioProcessor(mp3_file)
        transcription = audio_processor.process_audio()
        print(f"Transcription for {mp3_file}:\n{transcription}")

        # Train the model with data from Firebase
        classifier.train_model()

        # Use the model for prediction
        user_input = transcription
        predicted_intent = intent(classifier.model, classifier.vectorizer, user_input)  # Use the trained model and vectorizer for the given input
        print(f"Predicted Intent: {predicted_intent}")

        # main

        # Handle intents based on predicted intent (replace with actual logic)
        if predicted_intent == "caption" or predicted_intent == "image_assistant":
            storage_manager.download_file("images/latest.jpg", "/content/image_1.jpg")
            # Generate caption for a given image path
            image_caption_generator = ImageCaptionGenerator()
            output = image_caption_generator.predict_caption("/content/image_1.jpg")
            print(f"Generated Caption: {output}")

        elif predicted_intent == "greet" or predicted_intent == "natural_conversation":
            # Define a list of predefined messages to simulate interaction
            output = response = llama_bot.start_chat(user_input,"ahmed_said")
            print("llama BOT respon greeting :",output)

        elif predicted_intent == "general_knowledge":
            output = search_bot.answer_question("where is egypt", "first")
            print(f"General Knowledge Response: {output}")

        elif predicted_intent == "text_extraction":
            image_path = "/content/drive/MyDrive/_eyEar_/process_data/ocr.jpeg"
            extractor = ImageTextExtractor(image_path)
            output = extractor.extract_text_from_image()
            print(f"Extracted Text: {output}")

        elif predicted_intent == "time":
            # Show time and date in advanced formats
            output = time_zone_handler.get_current_date_in_full()
            print(f"Current Time: {output}")

        elif predicted_intent == "help":
            output = "How can I assist you today? Here are some options: greeting, time, text extraction, etc."
            print(output)

        else:
            output = "I'm sorry, I couldn't understand your request."
            print(output)

        print(output)
        # Example text-to-speech conversion and upload (replace with actual logic)
        lang = 'en'  # Language code, Arabic in this case
        # Create an instance of the TextToSpeechConverter class
        converter = TextToSpeechConverter(str(output), lang)

        # Call the process method to generate the speech
        converter.process()
        del converter

        # Upload the MP3 file and get the signed URL
        audio_mp3_url = storage_manager.upload_file("/content/output.mp3", "audio_out/output.mp3")
        if audio_mp3_url:
            print(f"Generated Signed URL for MP3: {audio_mp3_url}")

        # Upload the WAV file and get the signed URL
        audio_wav_url = storage_manager.upload_file("/content/output.wav", "audio_out/output.wav")
        if audio_wav_url:
            print(f"Generated Signed URL for WAV: {audio_wav_url}")
            # Clean up unused objects

        first_audio_repetition = 0
        db_ref.child("/voice/type").set(False)








try:
    main_loop()
except Exception as e :
    print(f"An error occurred: {e}")
    cleanup()



import gc

# قائمة الكائنات المراد حذفها
objects_to_delete = ["bot","image_caption_generator","llama_bot", "search_bot", "storage_manager", "time_zone_handler", "classifier"]

# حذف الكائنات إذا كانت موجودة
for obj_name in objects_to_delete:
    try:
        del globals()[obj_name]
    except :
        print(f"{obj_name} object was already deleted or not defined.")

# استدعاء جامع القمامة
freed_objects = gc.collect()

print(f"Garbage collector freed {freed_objects} unreachable objects.")


import psutil

# Get all processes
processes = []
for proc in psutil.process_iter(['pid', 'name', 'memory_info']):
    try:
        # Get memory usage in MB
        memory_usage = proc.info['memory_info'].rss / 1024 / 1024  # in MB
        processes.append((proc.info['pid'], proc.info['name'], memory_usage))
    except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess):
        continue

# Sort processes by memory usage in descending order
processes.sort(key=lambda x: x[2], reverse=True)

# Display the processes taking up the most RAM
print(f"{'PID':<10}{'Process Name':<30}{'Memory Usage (MB)'}")
for pid, name, memory_usage in processes[:10]:  # Show top 10 processes
    print(f"{pid:<10}{name:<30}{memory_usage:.2f}")
